{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor CDSS Demo\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/melmbrain/brain-tumor-cdss/blob/main/notebooks/demo.ipynb)\n",
    "\n",
    "This notebook demonstrates the Brain Tumor Clinical Decision Support System."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if running on Colab)\n",
    "# !pip install torch monai nibabel SimpleITK gseapy lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository (if running on Colab)\n",
    "# !git clone https://github.com/melmbrain/brain-tumor-cdss.git\n",
    "# %cd brain-tumor-cdss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.m1 import MRIMultiTaskModel, M1Inference\n",
    "from models.mg import GeneExpressionCDSS, MGInference\n",
    "from models.mm import MultimodalFusionModel, MMInference\n",
    "\n",
    "# Initialize models (will use random weights in demo mode)\n",
    "print(\"Loading M1 model...\")\n",
    "m1 = M1Inference(device='cpu')\n",
    "\n",
    "print(\"Loading MG model...\")\n",
    "mg = MGInference(device='cpu')\n",
    "\n",
    "print(\"Loading MM model...\")\n",
    "mm = MMInference(device='cpu')\n",
    "\n",
    "print(\"\\nAll models loaded (demo mode with random weights)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M1 Model Architecture\n",
    "m1_model = MRIMultiTaskModel(in_channels=4, embed_dim=48, include_segmentation=True)\n",
    "print(\"M1 Model (MRI Encoder):\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in m1_model.parameters()):,}\")\n",
    "print(f\"  Input: (B, 4, 128, 128, 128) - T1, T1ce, T2, FLAIR\")\n",
    "print(f\"  Output: Segmentation mask + Classification logits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MG Model Architecture\n",
    "gene_embeddings = torch.randn(500, 64)  # Placeholder\n",
    "mg_model = GeneExpressionCDSS(gene_embeddings=gene_embeddings, n_pathways=48)\n",
    "print(\"\\nMG Model (Gene VAE Encoder):\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in mg_model.parameters()):,}\")\n",
    "print(f\"  Input: 500 genes + 48 pathways\")\n",
    "print(f\"  Output: 64-dim latent + Task predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MM Model Architecture\n",
    "mm_model = MultimodalFusionModel(mri_dim=768, gene_dim=64, protein_dim=167, clinical_dim=10)\n",
    "print(\"\\nMM Model (Multimodal Fusion):\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in mm_model.parameters()):,}\")\n",
    "print(f\"  Input: MRI (768) + Gene (64) + Protein (167) + Clinical (10)\")\n",
    "print(f\"  Output: 7 classification tasks + Survival prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Demo: Gene Expression Analysis (MG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic gene expression data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate gene expression for 100 genes\n",
    "gene_names = [f'GENE_{i}' for i in range(100)]\n",
    "gene_expression = {name: np.random.randn() for name in gene_names}\n",
    "\n",
    "# Simulate pathway scores (Hallmark pathways)\n",
    "pathway_names = [\n",
    "    'HALLMARK_APOPTOSIS', 'HALLMARK_CELL_CYCLE', 'HALLMARK_DNA_REPAIR',\n",
    "    'HALLMARK_GLYCOLYSIS', 'HALLMARK_HYPOXIA', 'HALLMARK_P53_PATHWAY'\n",
    "]\n",
    "pathway_scores = {name: np.random.randn() for name in pathway_names}\n",
    "\n",
    "print(\"Sample gene expression data:\")\n",
    "for gene, value in list(gene_expression.items())[:5]:\n",
    "    print(f\"  {gene}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MG analysis\n",
    "result = mg.analyze(\n",
    "    patient_id=\"demo_patient\",\n",
    "    gene_expression=gene_expression,\n",
    "    pathway_scores=pathway_scores,\n",
    "    include_explainability=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MG Analysis Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nSurvival Risk: {result['survival_risk']['category']}\")\n",
    "print(f\"  Score: {result['survival_risk']['score']:.4f}\")\n",
    "print(f\"\\nGrade Prediction: {result['grade_prediction']['predicted']}\")\n",
    "print(f\"  Confidence: {result['grade_prediction']['confidence']:.3f}\")\n",
    "print(f\"\\nSurvival Time: {result['survival_time']['predicted_months']:.1f} months\")\n",
    "print(f\"\\nRecurrence: {result['recurrence']['prediction']}\")\n",
    "print(f\"  Probability: {result['recurrence']['probability']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Demo: Multimodal Fusion (MM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic multimodal features\n",
    "batch_size = 1\n",
    "\n",
    "# Pre-extracted features (normally from M1 and MG encoders)\n",
    "mri_features = torch.randn(batch_size, 768)   # From M1\n",
    "gene_features = torch.randn(batch_size, 64)   # From MG\n",
    "protein_data = torch.randn(batch_size, 167)   # RPPA\n",
    "clinical_data = torch.randn(batch_size, 10)   # Clinical features\n",
    "\n",
    "print(\"Input features:\")\n",
    "print(f\"  MRI: {mri_features.shape}\")\n",
    "print(f\"  Gene: {gene_features.shape}\")\n",
    "print(f\"  Protein: {protein_data.shape}\")\n",
    "print(f\"  Clinical: {clinical_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MM model\n",
    "with torch.no_grad():\n",
    "    outputs = mm_model(mri_features, gene_features, protein_data, clinical_data, return_attention=True)\n",
    "\n",
    "# Process outputs\n",
    "grade_probs = torch.softmax(outputs['grade_logits'], dim=-1).numpy()[0]\n",
    "idh_probs = torch.softmax(outputs['idh_logits'], dim=-1).numpy()[0]\n",
    "mgmt_probs = torch.softmax(outputs['mgmt_logits'], dim=-1).numpy()[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MM Multimodal Fusion Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nGrade Prediction:\")\n",
    "for i, grade in enumerate(['G1', 'G2', 'G3', 'G4']):\n",
    "    print(f\"  {grade}: {grade_probs[i]:.3f}\")\n",
    "print(f\"\\nIDH Mutation:\")\n",
    "print(f\"  Wildtype: {idh_probs[0]:.3f}\")\n",
    "print(f\"  Mutant: {idh_probs[1]:.3f}\")\n",
    "print(f\"\\nMGMT Methylation:\")\n",
    "print(f\"  Unmethylated: {mgmt_probs[0]:.3f}\")\n",
    "print(f\"  Methylated: {mgmt_probs[1]:.3f}\")\n",
    "print(f\"\\nSurvival:\")\n",
    "print(f\"  Risk Score: {torch.sigmoid(outputs['risk_score']).item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Attention Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get attention weights from MM model\n",
    "if 'modal_attention' in outputs:\n",
    "    attention = outputs['modal_attention'].numpy()[0]  # [num_heads, 4, 4]\n",
    "    \n",
    "    # Average over heads\n",
    "    avg_attention = attention.mean(axis=0)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    modalities = ['MRI', 'Gene', 'Protein', 'Clinical']\n",
    "    \n",
    "    plt.imshow(avg_attention, cmap='Blues', vmin=0, vmax=1)\n",
    "    plt.colorbar(label='Attention Weight')\n",
    "    plt.xticks(range(4), modalities)\n",
    "    plt.yticks(range(4), modalities)\n",
    "    plt.xlabel('Key')\n",
    "    plt.ylabel('Query')\n",
    "    plt.title('Cross-Modal Attention Weights')\n",
    "    \n",
    "    # Add values\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            plt.text(j, i, f'{avg_attention[i,j]:.2f}', ha='center', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Attention weights not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display reported performance metrics\n",
    "performance = {\n",
    "    'M1-Seg': {'Task': 'Segmentation', 'Metric': 'Dice', 'Score': 0.766},\n",
    "    'M1-Cls (IDH)': {'Task': 'IDH Mutation', 'Metric': 'AUC', 'Score': 0.878},\n",
    "    'M1-Cls (Grade)': {'Task': 'Grade Classification', 'Metric': 'Accuracy', 'Score': 0.838},\n",
    "    'M1-Cls (Survival)': {'Task': 'Survival', 'Metric': 'C-Index', 'Score': 0.660},\n",
    "    'MG': {'Task': 'Gene Survival', 'Metric': 'C-Index', 'Score': 0.780},\n",
    "    'MM': {'Task': 'Multimodal Survival', 'Metric': 'C-Index', 'Score': 0.610},\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Performance Summary\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Model':<20} {'Task':<25} {'Metric':<10} {'Score':<10}\")\n",
    "print(\"-\"*60)\n",
    "for model, metrics in performance.items():\n",
    "    print(f\"{model:<20} {metrics['Task']:<25} {metrics['Metric']:<10} {metrics['Score']:<10.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "1. **Download pretrained weights** from [Releases](https://github.com/melmbrain/brain-tumor-cdss/releases)\n",
    "2. **Prepare your data** using the preprocessing scripts\n",
    "3. **Run inference** with real patient data\n",
    "4. **Fine-tune models** on your own dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
